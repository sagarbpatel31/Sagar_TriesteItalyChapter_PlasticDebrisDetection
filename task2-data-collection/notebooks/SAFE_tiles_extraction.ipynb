{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a016576",
   "metadata": {},
   "source": [
    "#  Download full SAFE archive as .zip for acolite processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b61af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29b61131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Required satellite category\n",
    "query_satellite = 'SENTINEL-2'\n",
    "\n",
    "# 2 String to be included in filename for retrieval of specific product by name, \n",
    "# i.e L1C, and code for tile name\n",
    "query_product = 'S2A_MSIL1C_'\n",
    "query_tile = 'T33TUL'   # best tile for Po River Delta = 'T33TUL' -- other Po delta tiles (overlap) T33TUK, T32TQQ, T32TQR,\n",
    "# other AOIs: CALABRIA: 'T33SXC' | NE CORSICA  = 'T32TNN'\n",
    "\n",
    "# 3 Enter a start and end date\n",
    "query_startDate = '2019-07-01'\n",
    "query_endDate = '2019-07-31'\n",
    "\n",
    "# 4 Load geo.json polygon of area of interest: \n",
    "# map_geojson = './map.geojson'\n",
    "\n",
    "# 6 load your credentials from .env\n",
    "load_dotenv()\n",
    "username=os.getenv(\"CDSE_email\")\n",
    "password=os.getenv(\"CDSE_password\")\n",
    "# if not already in .env config, insert them as 'string' \n",
    "# values in the following format to the .env file:\n",
    "CDSE_email = username\n",
    "CDSE_password = password\n",
    "\n",
    "# 7 Set output file:\n",
    "output_dir = '../data/SAFE/March2019' #edit as appropriate to add batch folders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18550093",
   "metadata": {},
   "source": [
    "# Disclaimer ! ! !\n",
    "This code will query all records of the specified tile in the specified time period, without limiting whether windrows were annotated in the windrows catalogue. \n",
    "Cloud cover was hard set to be under 20%, which should limit the number of non-litter-row tiles, but this is no guarantee.\n",
    "The SAFE files should be checked against the LM_centroids/matched products before proceeding to acolite correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2c45810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_access_token(username: str, password: str) -> str:\n",
    "    data = {\n",
    "        \"client_id\": \"cdse-public\",\n",
    "        \"username\":username,\n",
    "        \"password\":password,\n",
    "        \"grant_type\": \"password\",\n",
    "        }\n",
    "    try:\n",
    "        r = requests.post(\n",
    "            \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n",
    "            data=data,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "    except Exception as e:\n",
    "        raise Exception(\n",
    "            f\"Access token creation failed. Reponse from the server was: {r.json()}\"\n",
    "            )\n",
    "    print(\"Access token created successfully!\")\n",
    "    return r.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b281cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_https_request(satellite, product, tile, start_date, end_date): #, geojson\n",
    "    \n",
    "    base_prefix = \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=\"\n",
    "    collection = \"Collection/Name eq '\" + satellite + \"' and startswith(Name,'\" + product + \"') and contains(Name,'\" + tile + \"')\"\n",
    "    #roi_coordinates = get_coordinates(geojson)\n",
    "    #geographic_criteria = \"OData.CSC.Intersects(area=geography'SRID=4326;POLYGON((\" + roi_coordinates + \"))') \"\n",
    "    content_date = (\n",
    "            \"ContentDate/Start gt \" + start_date + \"T00:00:00.000Z and \" +\n",
    "            \"ContentDate/Start lt \" + end_date + \"T00:00:00.000Z\"\n",
    "    )\n",
    "    https_request = ( base_prefix + collection +  \" and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le 20.00) and \" \n",
    "                     + content_date) # geographic_criteria + \" and \" +\n",
    "    print(\"Query URL:\", https_request)\n",
    "    return https_request\n",
    "\n",
    "\n",
    "def download_data(token, id, name, length, output):\n",
    "    url = f\"https://download.dataspace.copernicus.eu/odata/v1/Products({id})/$value\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "    response = session.get(url, headers=headers, stream=True)\n",
    "    try:\n",
    "        print('[', datetime.datetime.strftime(datetime.datetime.now(), '%H:%M:%S'), '] '+'Downloading: '+name)\n",
    "        with open(output, \"wb\") as file:\n",
    "            if length is not None:\n",
    "                # set the total length of the progress bar for tracking downloads\n",
    "                pbar = tqdm(total=length, unit=\"B\", unit_scale=True, desc=name)\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        file.write(chunk)\n",
    "                        # update progress bar\n",
    "                        pbar.update(len(chunk))\n",
    "                pbar.close()\n",
    "        print('[', datetime.datetime.strftime(datetime.datetime.now(), '%H:%M:%S'), '] '+'Download complete: '+name)\n",
    "        response.close()\n",
    "    except Exception as e:\n",
    "        print('[', datetime.datetime.strftime(datetime.datetime.now(), '%H:%M:%S'), '] '+'Download failed: '+name)\n",
    "        print(f\"An exception occured: {e}\")\n",
    "\n",
    "\n",
    "# zip the Safe files for download\n",
    "def get_file_name(name):\n",
    "    file_name = ''\n",
    "    if query_satellite == 'SENTINEL-1':\n",
    "        file_name = name.replace(\".SAFE\", \".zip\")\n",
    "    elif query_satellite == 'SENTINEL-2':\n",
    "        file_name = name.replace(\".SAFE\", \".zip\")\n",
    "    elif query_satellite == 'SENTINEL-3':\n",
    "        file_name = name.replace(\".SEN3\", \".zip\")\n",
    "    elif query_satellite == 'SENTINEL-5P':\n",
    "        file_name = name.replace(\".nc\", \".zip\")\n",
    "    elif query_satellite == 'SENTINEL-6':\n",
    "        file_name = name.replace(\".SEN6\", \".zip\")\n",
    "    return file_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8e7617",
   "metadata": {},
   "source": [
    "Download non-duplicate tiles matched to litter row data. Make sure the path  for ```litterrows = pd.read_excel('../files/LM_centroids.xlsx')```is reflected in your folder structure or \n",
    "changed to './LM_centroids.xlsx' if you have the folder in you content folder in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3610dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "request_url = get_https_request(\n",
    "    query_satellite, query_product, query_tile, query_startDate, query_endDate #, map_geojson, \n",
    ")\n",
    "JSON = requests.get(request_url).json()\n",
    "if 'detail' in JSON:\n",
    "    print(JSON['detail']['message'])\n",
    "    sys.exit()\n",
    "elif 'value' in JSON:\n",
    "    df = pd.DataFrame.from_dict(JSON['value'])\n",
    "    # print(df.columns)\n",
    "    if len(df) == 0:\n",
    "        print('No data found')\n",
    "        sys.exit()\n",
    "    \n",
    "    data_id_list = df.Id\n",
    "    data_name_list = df.Name\n",
    "    date_content_length = df.ContentLength\n",
    "else:\n",
    "    print('Unknown query error')\n",
    "    sys.exit()\n",
    "\n",
    "for i in range(len(data_id_list)):\n",
    "    print(data_name_list[i])\n",
    "    data_id = data_id_list[i]\n",
    "    data_name = get_file_name(data_name_list[i])\n",
    "    data_length = date_content_length[i]\n",
    "    # Check if the data storage path exists. If not, create the data storage path.\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    output_file = os.path.join(output_dir, data_name)\n",
    "    # # Check if the file has been downloaded before of it has no recorded windrows, in either case, skip it and do not download it (again).\n",
    "    litterrows = pd.read_excel('../files/LM_centroids.xlsx')\n",
    "    samples_set = set(litterrows['Str_time'])\n",
    "    if os.path.exists(output_file) and os.path.getsize(output_file) == data_length:\n",
    "        print(output_file + 'File already exists')   \n",
    "    elif output_file[34:49] not in samples_set:\n",
    "        print(output_file + ' has no recorded litter rows' )\n",
    "    else:\n",
    "        access_token = get_access_token(CDSE_email, CDSE_password)\n",
    "        download_data(access_token, data_id, data_name, data_length, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f917b5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-2' and startswith(Name,'S2A_MSIL1C_') and contains(Name,'T33TUL') and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le 20.00) and ContentDate/Start gt 2019-07-01T00:00:00.000Z and ContentDate/Start lt 2019-07-31T00:00:00.000Z\n"
     ]
    }
   ],
   "source": [
    "print(request_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omdena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
